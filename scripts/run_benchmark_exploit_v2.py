#!/usr/bin/env python3
"""Run exploit generation against benchmark cases from benchmark.csv (V2).

Usage:
    # Run single case by index
    python scripts/run_benchmark_exploit_v2.py --index 0

    # Run single case by name
    python scripts/run_benchmark_exploit_v2.py --case bancor

    # Run all mainnet cases
    python scripts/run_benchmark_exploit_v2.py --chain mainnet

    # Run with custom model
    python scripts/run_benchmark_exploit_v2.py --index 0 --model google/gemini-3-flash-preview

    # Run first N cases
    python scripts/run_benchmark_exploit_v2.py --chain mainnet --limit 5
"""

from __future__ import annotations

import argparse
import json
import os
import signal
import sys
import time
import traceback
from datetime import datetime, timezone
from pathlib import Path


def _now_iso() -> str:
    return datetime.now(timezone.utc).replace(microsecond=0).isoformat().replace("+00:00", "Z")


def _serialize_value(value):
    if isinstance(value, Path):
        return str(value)
    return value


def _serialize_args(args: argparse.Namespace) -> dict:
    return {key: _serialize_value(value) for key, value in vars(args).items()}


def _safe_write_json(path: Path, data: dict) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    tmp_path = path.with_name(path.name + ".tmp")
    tmp_path.write_text(json.dumps(data, indent=2))
    tmp_path.replace(path)


def _mask_api_key(url: str) -> str:
    import re

    url = re.sub(r"(/v[0-9]+/)[a-zA-Z0-9_-]{10,}", r"\1****", url)
    url = re.sub(r"(api[_-]?key=)[a-zA-Z0-9_-]+", r"\1****", url, flags=re.IGNORECASE)
    return re.sub(r"(/)[a-f0-9]{32,}(/|$)", r"\1****\2", url)


def _summarize_cases(cases: list[dict], planned: int) -> dict:
    summary = {
        "planned": planned,
        "completed": 0,
        "success": 0,
        "failed": 0,
        "interrupted": 0,
        "running": 0,
    }
    for case in cases:
        status = case.get("status")
        if status in {"success", "failed", "interrupted", "skipped"}:
            summary["completed"] += 1
        if status == "success":
            summary["success"] += 1
        elif status == "failed":
            summary["failed"] += 1
        elif status == "interrupted":
            summary["interrupted"] += 1
        elif status == "running":
            summary["running"] += 1
    return summary


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="Run exploit generation against benchmark cases.",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__,
    )

    # Case selection
    case_group = parser.add_mutually_exclusive_group()
    case_group.add_argument(
        "--index", type=int, default=None, help="Run case by row index (0-based)"
    )
    case_group.add_argument(
        "--case", type=str, default=None, help="Run case by name (e.g., 'bancor')"
    )

    # Filtering
    parser.add_argument(
        "--chain",
        type=str,
        default=None,
        choices=["mainnet", "bsc", "base"],
        help="Filter by chain (mainnet, bsc, base)",
    )
    parser.add_argument(
        "--limit", type=int, default=None, help="Limit number of cases to run"
    )

    # Runtime configuration
    parser.add_argument("--output", type=Path, default=None, help="Output directory for results")
    parser.add_argument("--config", type=str, default=None, help="Agent config name or path")
    parser.add_argument("--model", type=str, default=None, help="Model name override")
    parser.add_argument("--image", type=str, default=None, help="Docker image override")
    parser.add_argument("--cost-limit", type=float, default=None, help="Cost limit per episode")

    # Behavior
    parser.add_argument("--no-yolo", action="store_true", help="Disable yolo mode (require confirmations)")
    parser.add_argument(
        "--interactive", dest="interactive", action="store_true", help="Use interactive agent"
    )
    parser.add_argument(
        "--no-interactive", dest="interactive", action="store_false", help="Force default agent"
    )
    parser.add_argument("--env-file", type=Path, default=None, help="Path to .env file")
    parser.add_argument("--benchmark-csv", type=Path, default=None, help="Path to benchmark.csv")
    parser.add_argument("--cache-dir", type=Path, default=None, help="Directory to cache fetched sources")
    parser.add_argument(
        "-v", "--verbose", action="store_true", help="Enable verbose logging for debugging"
    )

    parser.set_defaults(interactive=False)
    return parser.parse_args()


def main() -> int:
    args = parse_args()
    project_root = Path(__file__).parent.parent
    sys.path.insert(0, str(project_root))

    # Import after path setup
    from exploit_generation.benchmark import (
        enrich_case_with_source,
        filter_by_chain,
        get_case_by_name,
        load_benchmark,
    )
    from exploit_generation.benchmark_episode import (
        BenchmarkEpisodeConfig,
        configure_logging,
        get_rpc_urls,
        load_env,
        parse_balance_wei,
        run_benchmark_exploit_episode,
    )

    # Configure logging first
    configure_logging(verbose=args.verbose)

    # Load environment
    env_file = args.env_file or (project_root / ".env")
    if env_file.exists():
        load_env(env_file)
        print(f"Loaded environment from {env_file}")
    else:
        load_env()
        print(f"Warning: No .env file found at {env_file}")

    # Validate API keys
    api_key = os.getenv("OPENROUTER_API_KEY")
    if not api_key:
        print("Error: OPENROUTER_API_KEY not set")
        return 1

    etherscan_key = os.getenv("ETHERSCAN_API_KEY")
    if not etherscan_key:
        print("Warning: ETHERSCAN_API_KEY not set, source fetching may fail")

    # Get model name
    model_name = args.model or os.getenv("OPENROUTER_MODEL_NAME") or os.getenv("MSWEA_MODEL_NAME")
    if not model_name:
        print("Error: Model name not set (--model or OPENROUTER_MODEL_NAME/MSWEA_MODEL_NAME env)")
        return 1

    # Load benchmark cases
    benchmark_csv = args.benchmark_csv or (project_root / "benchmark.csv")
    if not benchmark_csv.exists():
        print(f"Error: benchmark.csv not found at {benchmark_csv}")
        return 1

    cases = load_benchmark(benchmark_csv)
    print(f"Loaded {len(cases)} benchmark cases")

    # Filter by chain (initially only mainnet and bsc supported)
    supported_chains = ["mainnet", "bsc"]
    if args.chain:
        if args.chain not in supported_chains:
            print(f"Warning: Chain '{args.chain}' may not be fully supported. Supported: {supported_chains}")
        cases = filter_by_chain(cases, args.chain)
    else:
        # Default: filter to supported chains only
        cases = [c for c in cases if c.chain in supported_chains]

    print(f"After chain filter: {len(cases)} cases")

    # Select specific case
    if args.index is not None:
        if args.index < 0 or args.index >= len(cases):
            print(f"Error: Index {args.index} out of range (0-{len(cases) - 1})")
            return 1
        cases = [cases[args.index]]
    elif args.case:
        case = get_case_by_name(cases, args.case)
        if not case:
            print(f"Error: Case '{args.case}' not found")
            return 1
        cases = [case]

    # Apply limit
    if args.limit:
        cases = cases[: args.limit]

    if not cases:
        print("No cases to run")
        return 0

    print(f"Running {len(cases)} case(s):")
    for i, c in enumerate(cases):
        print(f"  [{i}] {c.case_name} ({c.chain}, block {c.fork_block_number})")

    # Get RPC URLs
    rpc_urls = get_rpc_urls()
    for chain in ["mainnet", "bsc"]:
        if chain not in rpc_urls:
            print(f"Warning: No RPC URL for {chain}")

    # Configuration
    output_dir = args.output or Path(
        os.getenv("EXPLOIT_OUTPUT_DIR_V2", os.getenv("EXPLOIT_OUTPUT_DIR", "exploit_results_v2"))
    )
    config_path = args.config or os.getenv(
        "EXPLOIT_CONFIG_V2", os.getenv("EXPLOIT_CONFIG", "benchmark_exploit_v2.yaml")
    )
    docker_image = args.image or os.getenv("EXPLOIT_DOCKER_IMAGE", "yudai-base:latest")
    cost_limit = args.cost_limit or float(
        os.getenv("EXPLOIT_COST_LIMIT_V2", os.getenv("EXPLOIT_COST_LIMIT", "20.0"))
    )

    # Player configuration
    player_address = os.getenv("PLAYER_ADDRESS")
    if not player_address:
        # Use a default test address
        player_address = "0xf39Fd6e51aad88F6F4ce6aB8827279cffFb92266"
        print(f"Using default player address: {player_address}")

    balance_wei_env = os.getenv("PLAYER_BALANCE_WEI")
    balance_eth_env = os.getenv("PLAYER_BALANCE_ETH")
    if balance_wei_env:
        player_balance_wei = parse_balance_wei(balance_wei_env)
    elif balance_eth_env:
        player_balance_wei = int(float(balance_eth_env) * 10**18)
    else:
        player_balance_wei = 100000 * 10**18  # 100k ETH

    # Cache directory for source code
    cache_dir = args.cache_dir or (project_root / "cache" / "sources")
    output_dir.mkdir(parents=True, exist_ok=True)

    run_id = f"benchmark_{time.strftime('%Y%m%d_%H%M%S')}_{os.getpid()}"
    run_summary_path = output_dir / f"{run_id}.json"
    masked_rpc_urls = {chain: _mask_api_key(url) for chain, url in rpc_urls.items()}
    run_summary = {
        "run_id": run_id,
        "status": "running",
        "started_at": _now_iso(),
        "finished_at": None,
        "script": "scripts/run_benchmark_exploit.py",
        "args": _serialize_args(args),
        "settings": {
            "benchmark_csv": str(benchmark_csv),
            "output_dir": str(output_dir),
            "config_path": str(config_path),
            "model_name": model_name,
            "docker_image": docker_image,
            "cost_limit": cost_limit,
            "player_address": player_address,
            "player_balance_wei": player_balance_wei,
            "rpc_urls": masked_rpc_urls,
            "cache_dir": str(cache_dir),
        },
        "summary": _summarize_cases([], planned=len(cases)),
        "cases": [],
    }
    _safe_write_json(run_summary_path, run_summary)
    print(f"Run log: {run_summary_path}")

    # Run cases
    results = []
    interrupted_signal = None
    current_case_record = None
    current_case_start = None

    def _handle_interrupt(signum, _frame):
        nonlocal interrupted_signal
        try:
            interrupted_signal = signal.Signals(signum).name
        except ValueError:
            interrupted_signal = str(signum)
        raise KeyboardInterrupt

    signal.signal(signal.SIGINT, _handle_interrupt)
    signal.signal(signal.SIGTERM, _handle_interrupt)

    try:
        for i, case in enumerate(cases):
            case_record = {
                "index": i,
                "case_name": case.case_name,
                "chain": case.chain,
                "fork_block_number": case.fork_block_number,
                "target_contract_address": case.target_contract_address,
                "status": "running",
                "started_at": _now_iso(),
                "finished_at": None,
                "duration_sec": None,
                "episode_id": None,
                "traj_path": None,
                "result_path": None,
                "metrics": {},
                "error": None,
            }
            run_summary["cases"].append(case_record)
            run_summary["summary"] = _summarize_cases(run_summary["cases"], planned=len(cases))
            _safe_write_json(run_summary_path, run_summary)

            current_case_record = case_record
            current_case_start = time.time()

            print(f"\n{'=' * 60}")
            print(f"[{i + 1}/{len(cases)}] Running: {case.case_name}")
            print(f"  Target: {case.target_contract_address}")
            print(f"  Chain: {case.chain}, Block: {case.fork_block_number}")
            print("=" * 60)

            try:
                # Fetch source code if not already present
                if not case.source_code:
                    print("Fetching source code from Etherscan...")
                    case = enrich_case_with_source(case, cache_dir=cache_dir)
                    if not case.source_code:
                        error_message = "Failed to fetch source code"
                        print(f"Error: {error_message} for {case.case_name}")
                        case_record["status"] = "failed"
                        case_record["error"] = {
                            "type": "SourceFetchError",
                            "message": error_message,
                        }
                        results.append(
                            {
                                "case_name": case.case_name,
                                "success": False,
                                "error": error_message,
                            }
                        )
                        continue
                    print(f"Source code fetched: {len(case.source_code)} chars")

                if case.source_code:
                    case_record["source_length"] = len(case.source_code)

                case_slug = case.case_name.replace(" ", "_")
                episode_id = f"{run_id}_{i + 1}_{case_slug}"
                case_record["episode_id"] = episode_id
                case_record["traj_path"] = str(output_dir / f"{episode_id}.traj.json")
                case_record["result_path"] = str(output_dir / f"{episode_id}.result.json")

                episode_config = BenchmarkEpisodeConfig(
                    case=case,
                    output_dir=output_dir,
                    model_name=model_name,
                    config_path=config_path,
                    docker_image=docker_image,
                    cost_limit=cost_limit,
                    player_address=player_address,
                    player_balance_wei=player_balance_wei,
                    rpc_urls=rpc_urls,
                    yolo=not args.no_yolo,
                    interactive=args.interactive,
                    episode_id=episode_id,
                )

                result = run_benchmark_exploit_episode(episode_config)

                print(f"\nResult for {case.case_name}:")
                print(f"  Success: {result.success}")
                print(f"  Profit: {result.profit_native_token:.6f}")
                print(f"  Cost: ${result.total_cost_usd:.4f}")
                print(f"  Iterations: {result.iterations}")

                case_record["status"] = "success" if result.success else "failed"
                case_record["metrics"] = {
                    "profit_native_token": result.profit_native_token,
                    "total_cost_usd": result.total_cost_usd,
                    "iterations": result.iterations,
                }
                case_record["episode_id"] = result.episode_id
                case_record["traj_path"] = str(output_dir / f"{result.episode_id}.traj.json")
                case_record["result_path"] = str(output_dir / f"{result.episode_id}.result.json")

                results.append(
                    {
                        "case_name": case.case_name,
                        "success": result.success,
                        "profit": result.profit_native_token,
                        "cost": result.total_cost_usd,
                        "episode_id": result.episode_id,
                    }
                )

            except Exception as e:
                print(f"Error running {case.case_name}: {e}")
                traceback.print_exc()
                case_record["status"] = "failed"
                case_record["error"] = {
                    "type": type(e).__name__,
                    "message": str(e),
                    "traceback": traceback.format_exc(),
                }
                results.append(
                    {
                        "case_name": case.case_name,
                        "success": False,
                        "error": str(e),
                    }
                )

            finally:
                case_record["finished_at"] = _now_iso()
                if current_case_start is not None:
                    case_record["duration_sec"] = round(time.time() - current_case_start, 3)
                run_summary["summary"] = _summarize_cases(run_summary["cases"], planned=len(cases))
                _safe_write_json(run_summary_path, run_summary)

            current_case_record = None
            current_case_start = None

    except KeyboardInterrupt:
        run_summary["status"] = "interrupted"
        run_summary["interrupt_signal"] = interrupted_signal or "SIGINT"
        if current_case_record is not None:
            current_case_record["status"] = "interrupted"
            current_case_record["error"] = {
                "type": "KeyboardInterrupt",
                "message": "Run interrupted by user",
                "traceback": traceback.format_exc(),
            }
            current_case_record["finished_at"] = _now_iso()
            if current_case_start is not None:
                current_case_record["duration_sec"] = round(time.time() - current_case_start, 3)
        run_summary["finished_at"] = _now_iso()
        run_summary["summary"] = _summarize_cases(run_summary["cases"], planned=len(cases))
        _safe_write_json(run_summary_path, run_summary)
        print(f"\nRun interrupted. Summary saved to {run_summary_path}")
        return 130

    except Exception as e:
        run_summary["status"] = "failed"
        run_summary["finished_at"] = _now_iso()
        run_summary["fatal_error"] = {
            "type": type(e).__name__,
            "message": str(e),
            "traceback": traceback.format_exc(),
        }
        run_summary["summary"] = _summarize_cases(run_summary["cases"], planned=len(cases))
        _safe_write_json(run_summary_path, run_summary)
        print(f"Error: {e}")
        traceback.print_exc()
        return 1

    run_summary["status"] = "completed"
    run_summary["finished_at"] = _now_iso()
    run_summary["summary"] = _summarize_cases(run_summary["cases"], planned=len(cases))
    _safe_write_json(run_summary_path, run_summary)

    # Summary
    print(f"\n{'=' * 60}")
    print("SUMMARY")
    print("=" * 60)
    successful = sum(1 for r in results if r.get("success", False))
    print(f"Total: {len(results)}, Successful: {successful}, Failed: {len(results) - successful}")

    for r in results:
        status = "SUCCESS" if r.get("success") else "FAILED"
        profit = r.get("profit", 0)
        print(f"  [{status}] {r['case_name']}: profit={profit:.6f}")

    return 0 if successful > 0 else 1


if __name__ == "__main__":
    raise SystemExit(main())
